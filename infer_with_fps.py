import cv2
import torch
import time
import torchvision
import numpy as np
from collections import deque
from tqdm import tqdm
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

# ==== CONFIG ====
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
num_classes = 12
model_path = "models/c2a_best_model.pth" # Sแปญ dแปฅng model tแปt nhแบฅt
input_video = "test_video.mp4"
output_video = "output_fps_benchmark.avi"
threshold = 0.5

# ==== Load model ====
print("Loading model...")
model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=None)
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device).eval()
print("โ Model loaded successfully")

# ======================================================================
# WARM-UP GIAI ฤOแบN (Rแบฅt quan trแปng ฤแป cรณ kแบฟt quแบฃ ฤo chรญnh xรกc)
# ======================================================================
if device.type == 'cuda':
    print("๐ Warming up the GPU...")
    # Tแบกo mแปt tensor giแบฃ cรณ kรญch thฦฐแปc tฦฐฦกng tแปฑ แบฃnh ฤแบงu vรo
    dummy_input = torch.randn(1, 3, 480, 640, device=device)
    for _ in range(10):
        with torch.no_grad():
            model(dummy_input)
    # ฤแบฃm bแบฃo tแบฅt cแบฃ cรกc tรกc vแปฅ warm-up ฤรฃ hoรn thรnh
    torch.cuda.synchronize()
    print("โ GPU is warm.")

# ==== Load video ====
cap = cv2.VideoCapture(input_video)
if not cap.isOpened():
    raise RuntimeError(f"โ Could not open video {input_video}")

frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))

# Biแบฟn ฤแป tรญnh toรกn hiแปu suแบฅt
model_latencies = []
end_to_end_times = []
# Sแปญ dแปฅng deque ฤแป tรญnh FPS trung bรฌnh trฦฐแปฃt (moving average) cho mฦฐแปฃt
fps_smoother = deque(maxlen=30) 

print("๐ Running inference and benchmarking FPS...")
progress_bar = tqdm(total=total_frames, desc="Processing video")

while True:
    loop_start_time = time.time()
    ret, frame = cap.read()
    if not ret:
        break

    # --- Pre-processing ---
    img_tensor = torchvision.transforms.functional.to_tensor(frame).to(device)

    # --- Model Inference (ฤo lฦฐแปng chรญnh xรกc) ---
    torch.cuda.synchronize() # ฤแบฃm bแบฃo cรกc tรกc vแปฅ trฦฐแปc ฤรณ ฤรฃ xong
    inference_start = time.time()
    
    with torch.no_grad():
        pred = model([img_tensor])[0]
        
    # ====> ฤรY Lร DรNG QUAN TRแปNG NHแบคT <====
    torch.cuda.synchronize() # Buแปc CPU ฤแปฃi GPU hoรn thรnh
    inference_end = time.time()
    
    model_latency = inference_end - inference_start
    model_latencies.append(model_latency)

    # --- Post-processing ---
    boxes = pred["boxes"].cpu().numpy()
    scores = pred["scores"].cpu().numpy()
    labels = pred["labels"].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        if score < threshold:
            continue
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        # cv2.putText(frame, f"Obj {label.item()} {score:.2f}", ... ) # (Bแบกn cรณ thแป thรชm lแบกi nแบฟu muแปn)

    # --- Hiแปn thแป FPS (ฤรฃ lรm mฦฐแปฃt) ---
    loop_end_time = time.time()
    end_to_end_time = loop_end_time - loop_start_time
    end_to_end_times.append(end_to_end_time)
    
    # Tรญnh FPS trung bรฌnh cแปงa 30 frame gแบงn nhแบฅt
    fps_smoother.append(end_to_end_time)
    smooth_fps = 1.0 / np.mean(fps_smoother)

    cv2.putText(frame, f"FPS: {smooth_fps:.2f}", (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
    out.write(frame)
    progress_bar.update(1)

# --- Dแปn dแบนp vร In kแบฟt quแบฃ ---
cap.release()
out.release()
progress_bar.close()

# Tรญnh toรกn cรกc chแป sแป trung bรฌnh
avg_model_latency_ms = np.mean(model_latencies) * 1000
avg_model_fps = 1.0 / np.mean(model_latencies)
avg_end_to_end_fps = 1.0 / np.mean(end_to_end_times)

print(f"\nโ Done! Video saved to {output_video}")
print("="*30)
print("๐ BENCHMARK RESULTS ๐")
print("="*30)
print(f"โฑ๏ธ Model Inference Latency: {avg_model_latency_ms:.2f} ms/frame")
print(f"๐ Model Throughput:        {avg_model_fps:.2f} FPS")
print(f"๐ฌ End-to-End Throughput:   {avg_end_to_end_fps:.2f} FPS")
print("="*30)