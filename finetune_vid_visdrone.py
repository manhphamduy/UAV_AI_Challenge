import os
import torch
import torchvision
from torch.utils.data import DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import torchvision.transforms.v2 as T # Sá»¬ Dá»¤NG transforms v2
from tqdm import tqdm

# Äáº£m báº£o báº¡n Ä‘ang dÃ¹ng file dataset Ä‘Ã£ Ä‘Æ°á»£c cáº£i tiáº¿n
from dataset_visdrone_vid import VisDroneVideoDataset 
from evaluate import evaluate_model

# ======================================================================
# ==== CONFIG ====
# ======================================================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# --- Cáº¥u hÃ¬nh Dataset & Model ---
num_classes = 12  # 11 lá»›p cá»§a VisDrone + 1 lá»›p background
IMG_SIZE = 640    # KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o, quan trá»ng cho váº­t thá»ƒ nhá»

# --- Cáº¥u hÃ¬nh Training ---
TOTAL_EPOCHS = 40       # TÄ‚NG Sá» EPOCHS LÃŠN ÄÃNG Ká»‚
batch_size = 2          # Giáº£m náº¿u gáº·p lá»—i Out of Memory (OOM) khi tÄƒng IMG_SIZE
LR_HEAD = 1e-4          # Learning rate cho RPN vÃ  RoI Heads (cao hÆ¡n)
LR_BACKBONE = 1e-5      # Learning rate cho Backbone (tháº¥p hÆ¡n 10 láº§n)
WEIGHT_DECAY = 1e-4     # Sá»­ dá»¥ng weight decay vá»›i AdamW
GRADIENT_CLIP_NORM = 1.0

# --- ÄÆ°á»ng dáº«n ---
train_path = "data/VisDrone2019-VID-train"
val_path = "data/VisDrone2019-VID-val"
# Model nÃ y lÃ  káº¿t quáº£ tá»« viá»‡c train trÃªn táº­p áº£nh tÄ©nh (náº¿u cÃ³)
pretrained_model_path = "models/img_best_model.pth" 
vid_model_path = "models/vid_best_model.pth"
# Äá»•i tÃªn checkpoint Ä‘á»ƒ khÃ´ng ghi Ä‘Ã¨ lÃªn file cÅ©
checkpoint_path = "models/vid_checkpoint_v2.pth" 

# ======================================================================
# ==== DATASET & AUGMENTATION ====
# ======================================================================
print("Setting up data augmentation and dataloaders...")
# Pipeline transform cho training (bao gá»“m augmentation)
transform_train = T.Compose([
    T.ToImage(),
    T.ToDtype(torch.float32, scale=True),
    T.Resize((IMG_SIZE, IMG_SIZE), antialias=True), # Resize áº£nh vÃ  bounding box
    T.RandomHorizontalFlip(p=0.5),
    # CÃ³ thá»ƒ thÃªm ColorJitter Ä‘á»ƒ tÄƒng Ä‘á»™ khÃ³, nhÆ°ng hÃ£y thá»­ khÃ´ng cÃ³ nÃ³ trÆ°á»›c
    # T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
])

# Pipeline transform cho validation (chá»‰ resize vÃ  chuáº©n hÃ³a)
transform_val = T.Compose([
    T.ToImage(),
    T.ToDtype(torch.float32, scale=True),
    T.Resize((IMG_SIZE, IMG_SIZE), antialias=True),
])

# Khá»Ÿi táº¡o Dataset
train_dataset = VisDroneVideoDataset(train_path, transforms=transform_train)
val_dataset = VisDroneVideoDataset(val_path, transforms=transform_val)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)), num_workers=4, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)), num_workers=4, pin_memory=True)
print("âœ… Data setup complete.")

# ======================================================================
# ==== MODEL, OPTIMIZER, SCHEDULER ====
# ======================================================================
print("Setting up model, optimizer, and scheduler...")
# Sá»­ dá»¥ng model Ä‘Ã£ pre-train trÃªn COCO
model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights="DEFAULT")
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# Load model Ä‘Ã£ Ä‘Æ°á»£c fine-tune trÃªn áº£nh tÄ©nh (náº¿u cÃ³)
if os.path.exists(pretrained_model_path):
    print(f"ðŸ”„ Loading pretrained weights from {pretrained_model_path}")
    model.load_state_dict(torch.load(pretrained_model_path, map_location=device))
else:
    print("âš ï¸ Pretrained model not found. Using default COCO weights.")

model.to(device)

# --- PhÃ¢n chia parameters cho Differential Learning Rates ---
backbone_params = [p for name, p in model.named_parameters() if 'backbone' in name and p.requires_grad]
head_params = [p for name, p in model.named_parameters() if 'backbone' not in name and p.requires_grad]

param_groups = [
    {'params': backbone_params, 'lr': LR_BACKBONE},
    {'params': head_params, 'lr': LR_HEAD}
]

# --- Optimizer vÃ  Scheduler ---
optimizer = torch.optim.AdamW(param_groups, weight_decay=WEIGHT_DECAY)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TOTAL_EPOCHS, eta_min=1e-6)
print("âœ… Model setup complete.")

# ======================================================================
# ==== CHECKPOINT LOADING ====
# ======================================================================
start_epoch = 0
best_map = 0.0
if os.path.exists(checkpoint_path):
    print(f"ðŸ“‚ Loading checkpoint from {checkpoint_path}")
    ckpt = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(ckpt['model_state'])
    optimizer.load_state_dict(ckpt['optimizer_state'])
    scheduler.load_state_dict(ckpt['scheduler_state'])
    start_epoch = ckpt['epoch'] + 1
    best_map = ckpt.get('best_map', 0.0) # DÃ¹ng .get Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i checkpoint cÅ©
    print(f"âœ… Resumed from epoch {start_epoch}, best_map={best_map:.4f}")
else:
    print("ðŸš€ Starting training from scratch.")

# ======================================================================
# ==== TRAINING LOOP ====
# ======================================================================
print(f"\nðŸ”¥ === Starting Training ({TOTAL_EPOCHS} Epochs) ===")
for epoch in range(start_epoch, TOTAL_EPOCHS):
    model.train()
    total_loss = 0.0
    
    # Láº¥y LR hiá»‡n táº¡i cá»§a head Ä‘á»ƒ hiá»ƒn thá»‹
    current_lr = optimizer.param_groups[1]['lr']
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{TOTAL_EPOCHS} (LR={current_lr:.1e})")

    for images, targets in progress_bar:
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        
        # Check for invalid loss
        if not torch.isfinite(losses):
            print(f"WARNING: Non-finite loss detected: {losses.item()}. Skipping batch.")
            continue
            
        optimizer.zero_grad()
        losses.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_NORM)
        optimizer.step()
        
        total_loss += losses.item()
        progress_bar.set_postfix(loss=f"{losses.item():.4f}")
    
    avg_loss = total_loss / len(train_loader)
    print(f"ðŸ“‰ Epoch {epoch+1} - Train Loss: {avg_loss:.4f}")
    
    # --- EVALUATION (Sau má»—i epoch) ---
    print(f"ðŸ“Š Evaluating...")
    mAP = evaluate_model(model, val_loader, device)
    print(f"ðŸ“Š Epoch {epoch+1} - Validation mAP: {mAP:.4f}")
    
    # --- Cáº­p nháº­t scheduler ---
    scheduler.step()
    
    # --- Save best model ---
    if mAP > best_map:
        best_map = mAP
        torch.save(model.state_dict(), vid_model_path)
        print(f"ðŸŒŸ New best model saved (mAP={best_map:.4f})")
    
    # --- Save checkpoint ---
    torch.save({
        'epoch': epoch,
        'model_state': model.state_dict(),
        'optimizer_state': optimizer.state_dict(),
        'scheduler_state': scheduler.state_dict(),
        'best_map': best_map,
    }, checkpoint_path)
    print(f"ðŸ’¾ Checkpoint saved for epoch {epoch+1}")

print(f"\nðŸŽ‰ Training complete! Best Validation mAP = {best_map:.4f}")