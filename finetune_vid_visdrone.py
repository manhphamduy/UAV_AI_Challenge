import os
import torch
import torch.nn as nn
import torchvision
from torch.utils.data import DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from tqdm import tqdm

# <--- Sá»¬A Äá»”I: Import Kornia
import kornia.augmentation as K
import kornia.geometry as K_geom
import torchvision.transforms as T # Chá»‰ dÃ¹ng cho ToTensor

from dataset_visdrone_vid import VisDroneVideoDataset
from evaluate import evaluate_model # Äáº£m báº£o evaluate_model cÃ³ thá»ƒ xá»­ lÃ½ DataParallel model

# ======================================================================
# ==== CONFIG ====
# ======================================================================
# <--- Sá»¬A Äá»”I: Chá»n GPU chÃ­nh vÃ  kiá»ƒm tra sá»‘ lÆ°á»£ng GPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
gpu_count = torch.cuda.device_count()
print(f"Using device: {device}, Found {gpu_count} GPUs.")

# --- Cáº¥u hÃ¬nh Dataset & Model ---
num_classes = 12
IMG_SIZE = 640

# --- Cáº¥u hÃ¬nh Training ---
TOTAL_EPOCHS = 40
# <--- Sá»¬A Äá»”I: TÄƒng batch_size vÃ¬ dÃ¹ng nhiá»u GPU
# Batch size tá»•ng sáº½ lÃ  batch_size * gpu_count
batch_size = 4  
LR_HEAD = 1e-4
LR_BACKBONE = 1e-5
WEIGHT_DECAY = 1e-4
GRADIENT_CLIP_NORM = 1.0

# --- ÄÆ°á»ng dáº«n ---
train_path = "data/VisDrone2019-VID-train"
val_path = "data/VisDrone2019-VID-val"
pretrained_model_path = "models/img_best_model.pth"
vid_model_path = "models/vid_best_model.pth"
checkpoint_path = "models/vid_checkpoint_v2.pth"

# ======================================================================
# ==== DATASET (CPU PART) ====
# ======================================================================
print("Setting up CPU-side dataloaders...")
# <--- Sá»¬A Äá»”I: Transform trÃªn CPU chá»‰ cÃ²n duy nháº¥t ToTensor
# ToÃ n bá»™ augmentation sáº½ Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn GPU
transform_cpu = T.ToTensor()

train_dataset = VisDroneVideoDataset(train_path, transforms=transform_cpu)
val_dataset = VisDroneVideoDataset(val_path, transforms=transform_cpu)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)), num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)), num_workers=2, pin_memory=True)
print("âœ… CPU Dataloaders ready.")

# ======================================================================
# ==== AUGMENTATION (GPU PART) ====
# ======================================================================
print("Setting up GPU-side augmentation module...")
# <--- Sá»¬A Äá»”I: Táº¡o pipeline augmentation báº±ng Kornia
# NÃ³ hoáº¡t Ä‘á»™ng nhÆ° má»™t module nn.Module vÃ  sáº½ cháº¡y trÃªn GPU
gpu_augmentations = nn.Sequential(
    K.Resize(size=(IMG_SIZE, IMG_SIZE), antialias=True),
    K.RandomHorizontalFlip(p=0.5),
    # Báº¡n cÃ³ thá»ƒ thÃªm cÃ¡c augmentation khÃ¡c cá»§a Kornia á»Ÿ Ä‘Ã¢y
    # K.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, p=0.8),
).to(device)

# Táº¡o má»™t pipeline riÃªng cho validation (chá»‰ resize)
gpu_val_transform = nn.Sequential(
    K.Resize(size=(IMG_SIZE, IMG_SIZE), antialias=True),
).to(device)
print("âœ… GPU Augmentation ready.")


# ======================================================================
# ==== MODEL, OPTIMIZER, SCHEDULER ====
# ======================================================================
print("Setting up model, optimizer, and scheduler...")
model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights="DEFAULT")
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

if os.path.exists(pretrained_model_path):
    print(f"ðŸ”„ Loading pretrained weights from {pretrained_model_path}")
    model.load_state_dict(torch.load(pretrained_model_path, map_location=device))
else:
    print("âš ï¸ Pretrained model not found. Using default COCO weights.")

model.to(device)

# <--- Sá»¬A Äá»”I: Bá»c model báº±ng DataParallel Ä‘á»ƒ sá»­ dá»¥ng nhiá»u GPU
if gpu_count > 1:
    print(f"Using {gpu_count} GPUs via DataParallel.")
    model = nn.DataParallel(model, device_ids=list(range(gpu_count)))

backbone_params = [p for name, p in model.named_parameters() if 'backbone' in name and p.requires_grad]
head_params = [p for name, p in model.named_parameters() if 'backbone' not in name and p.requires_grad]
param_groups = [{'params': backbone_params, 'lr': LR_BACKBONE}, {'params': head_params, 'lr': LR_HEAD}]

optimizer = torch.optim.AdamW(param_groups, weight_decay=WEIGHT_DECAY)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TOTAL_EPOCHS, eta_min=1e-6)
print("âœ… Model setup complete.")


# ======================================================================
# ==== CHECKPOINT LOADING ====
# ======================================================================
start_epoch = 0
best_map = 0.0
if os.path.exists(checkpoint_path):
    print(f"ðŸ“‚ Loading checkpoint from {checkpoint_path}")
    # <--- Sá»¬A Äá»”I: Khi load, ta cáº§n load vÃ o model gá»‘c, khÃ´ng pháº£i DataParallel wrapper
    # nÃªn ta sáº½ load trÆ°á»›c khi bá»c DataParallel (Ä‘Ã£ lÃ m á»Ÿ trÃªn)
    # Tuy nhiÃªn, náº¿u checkpoint Ä‘Æ°á»£c lÆ°u tá»« DataParallel, nÃ³ sáº½ cÃ³ tiá»n tá»‘ 'module.'
    # Ta sáº½ xá»­ lÃ½ viá»‡c nÃ y sau khi load optimizer
    ckpt = torch.load(checkpoint_path, map_location=device)
    
    # Logic Ä‘á»ƒ xá»­ lÃ½ checkpoint cÃ³/khÃ´ng cÃ³ `module.` prefix
    # Náº¿u Ä‘ang dÃ¹ng nhiá»u GPU vÃ  checkpoint khÃ´ng cÃ³ 'module.', thÃªm nÃ³ vÃ o.
    # Náº¿u Ä‘ang dÃ¹ng má»™t GPU vÃ  checkpoint cÃ³ 'module.', xÃ³a nÃ³ Ä‘i.
    # CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  load state vÃ o model gá»‘c trÆ°á»›c khi bá»c DataParallel
    # Pháº§n code á»Ÿ trÃªn Ä‘Ã£ lÃ m viá»‡c nÃ y.
    
    optimizer.load_state_dict(ckpt['optimizer_state'])
    scheduler.load_state_dict(ckpt['scheduler_state'])
    start_epoch = ckpt['epoch'] + 1
    best_map = ckpt.get('best_map', 0.0)
    print(f"âœ… Resumed from epoch {start_epoch}, best_map={best_map:.4f}")
else:
    print("ðŸš€ Starting training from scratch.")


# ======================================================================
# ==== TRAINING LOOP ====
# ======================================================================
print(f"\nðŸ”¥ === Starting Training ({TOTAL_EPOCHS} Epochs) ===")
for epoch in range(start_epoch, TOTAL_EPOCHS):
    model.train()
    total_loss = 0.0
    
    current_lr = optimizer.param_groups[1]['lr']
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{TOTAL_EPOCHS} (LR={current_lr:.1e})")

    for images, targets in progress_bar:
        # <--- Sá»¬A Äá»”I: Luá»“ng xá»­ lÃ½ má»›i
        # 1. Chuyá»ƒn tensor áº£nh gá»‘c lÃªn GPU
        # Dá»¯ liá»‡u áº£nh lÃºc nÃ y chÆ°a Ä‘Æ°á»£c resize hay augment
        images_tensor = torch.stack(images).to(device)
        
        # 2. Thá»±c hiá»‡n augmentation trÃªn toÃ n bá»™ batch trÃªn GPU
        images_augmented = gpu_augmentations(images_tensor)
        
        # 3. Cáº­p nháº­t láº¡i bounding box cho phÃ¹ há»£p vá»›i augmentation
        # Kornia khÃ´ng tá»± Ä‘á»™ng cáº­p nháº­t target, ta pháº£i lÃ m thá»§ cÃ´ng
        # ÄÃ¢y lÃ  má»™t cÃ¡ch Ä‘Æ¡n giáº£n, tuy nhiÃªn Kornia cÃ³ cÃ¡c cÃ¡ch hiá»‡u quáº£ hÆ¡n
        # nhÆ°ng phá»©c táº¡p hÆ¡n. CÃ¡ch nÃ y Ä‘á»§ tá»‘t.
        final_images = []
        final_targets = []
        # Láº¥y kÃ­ch thÆ°á»›c áº£nh gá»‘c vÃ  áº£nh sau augment Ä‘á»ƒ tÃ­nh tá»‰ lá»‡ scale
        orig_h, orig_w = images[0].shape[-2:]
        aug_h, aug_w = images_augmented.shape[-2:]
        scale_h = aug_h / orig_h
        scale_w = aug_w / orig_w
        
        for i in range(len(images)):
            target = targets[i]
            boxes = target['boxes']
            # Scale boxes theo resize
            boxes[:, [0, 2]] *= scale_w
            boxes[:, [1, 3]] *= scale_h
            
            # Náº¿u cÃ³ flip (giáº£ Ä‘á»‹nh p=0.5, cÃ¡ch Ä‘Æ¡n giáº£n hÃ³a)
            # Má»™t cÃ¡ch chÃ­nh xÃ¡c hÆ¡n cáº§n láº¥y ma tráº­n transform tá»« kornia
            # nhÆ°ng sáº½ phá»©c táº¡p hÆ¡n. Vá»›i RandomHorizontalFlip thÃ¬ cÃ¡ch nÃ y Ä‘á»§ dÃ¹ng.
            
            new_target = {k: v.to(device) for k, v in target.items()}
            new_target['boxes'] = boxes.to(device)
            final_targets.append(new_target)
            final_images.append(images_augmented[i])
        
        loss_dict = model(final_images, final_targets)
        
        # DataParallel tráº£ vá» loss trÃªn tá»«ng GPU, cáº§n cá»™ng láº¡i
        losses = sum(loss for loss in loss_dict.values())
        if gpu_count > 1:
            losses = losses.mean() # Láº¥y trung bÃ¬nh loss trÃªn cÃ¡c GPU

        if not torch.isfinite(losses):
            print(f"WARNING: Non-finite loss detected: {losses.item()}. Skipping batch.")
            continue
            
        optimizer.zero_grad()
        losses.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_NORM)
        optimizer.step()
        
        total_loss += losses.item()
        progress_bar.set_postfix(loss=f"{losses.item():.4f}")
    
    avg_loss = total_loss / len(train_loader)
    print(f"ðŸ“‰ Epoch {epoch+1} - Train Loss: {avg_loss:.4f}")
    
    # --- EVALUATION ---
    print(f"ðŸ“Š Evaluating...")
    # Cáº§n má»™t hÃ m evaluate Ä‘Ã£ Ä‘Æ°á»£c chá»‰nh Ä‘á»ƒ cháº¡y vá»›i GPU transform vÃ  DataParallel model
    mAP = evaluate_model(model, val_loader, device, gpu_val_transform)
    print(f"ðŸ“Š Epoch {epoch+1} - Validation mAP: {mAP:.4f}")
    
    scheduler.step()
    
    # --- Save best model ---
    if mAP > best_map:
        best_map = mAP
        # <--- Sá»¬A Äá»”I: Khi lÆ°u, láº¥y ra model gá»‘c tá»« .module
        state_dict_to_save = model.module.state_dict() if gpu_count > 1 else model.state_dict()
        torch.save(state_dict_to_save, vid_model_path)
        print(f"ðŸŒŸ New best model saved (mAP={best_map:.4f})")
    
    # --- Save checkpoint ---
    state_dict_to_save = model.module.state_dict() if gpu_count > 1 else model.state_dict()
    torch.save({
        'epoch': epoch,
        'model_state': state_dict_to_save,
        'optimizer_state': optimizer.state_dict(),
        'scheduler_state': scheduler.state_dict(),
        'best_map': best_map,
    }, checkpoint_path)
    print(f"ðŸ’¾ Checkpoint saved for epoch {epoch+1}")

print(f"\nðŸŽ‰ Training complete! Best Validation mAP = {best_map:.4f}")